{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e374afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange, einsum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a4546ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.7128,  0.3073],\n",
       "         [ 0.0575,  1.3462]],\n",
       "\n",
       "        [[-0.7967,  0.0265],\n",
       "         [ 0.5132,  1.6646]],\n",
       "\n",
       "        [[-0.8223,  0.3482],\n",
       "         [-0.7530,  0.8034]],\n",
       "\n",
       "        [[ 0.4352, -0.3029],\n",
       "         [ 2.5822, -2.9994]],\n",
       "\n",
       "        [[-0.5144,  0.3487],\n",
       "         [ 0.4417, -0.6248]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = torch.randn(5,2,3)\n",
    "A = torch.randn(2,3)\n",
    "D @ A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfa81af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.7128,  0.3073],\n",
       "         [ 0.0575,  1.3462]],\n",
       "\n",
       "        [[-0.7967,  0.0265],\n",
       "         [ 0.5132,  1.6646]],\n",
       "\n",
       "        [[-0.8223,  0.3482],\n",
       "         [-0.7530,  0.8034]],\n",
       "\n",
       "        [[ 0.4352, -0.3029],\n",
       "         [ 2.5822, -2.9994]],\n",
       "\n",
       "        [[-0.5144,  0.3487],\n",
       "         [ 0.4417, -0.6248]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 假设使用 einops.einsum\n",
    "# 修正后的 pattern：\n",
    "Y = einsum(D, A, \"batch sequence d_in, d_out d_in -> batch sequence d_out\")\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de9b9ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.7128,  0.3073],\n",
       "         [ 0.0575,  1.3462]],\n",
       "\n",
       "        [[-0.7967,  0.0265],\n",
       "         [ 0.5132,  1.6646]],\n",
       "\n",
       "        [[-0.8223,  0.3482],\n",
       "         [-0.7530,  0.8034]],\n",
       "\n",
       "        [[ 0.4352, -0.3029],\n",
       "         [ 2.5822, -2.9994]],\n",
       "\n",
       "        [[-0.5144,  0.3487],\n",
       "         [ 0.4417, -0.6248]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = einsum(D,A,\"... d_in, dout d_in -> ... dout\")\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4df3ade7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = torch.randn(64,128,128,3)\n",
    "dim_by = torch.linspace(start=0,end=1.0,steps=10)\n",
    "dim_by.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "086bdff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 128, 128, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_value = rearrange(dim_by, \"dim_value -> 1 dim_value 1 1 1\")\n",
    "images_rearr = rearrange(images, \"b height width channel -> b 1 height width channel\")\n",
    "dimmed_images = images_rearr * dim_value\n",
    "dimmed_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91dd7b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 128, 128, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimmed_images = einsum(images,dim_by,\"batch height width channel, dim_value -> batch dim_value height width channel\")\n",
    "dimmed_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "298cd396",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_last = torch.randn(64,32,32,3)\n",
    "B = torch.randn(32*32, 32*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4cedd6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 1024])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels_last_flat = channels_last.view(-1,channels_last.size(1) * channels_last.size(2),channels_last.size(3))\n",
    "channels_first_flat = channels_last_flat.transpose(1,2)\n",
    "channels_first_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "900af7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_first_flat_transformed = channels_first_flat @ B.T\n",
    "channels_last_flat_transformed = channels_first_flat_transformed.transpose(1,2)\n",
    "channels_last_flat_transformed = channels_last_flat_transformed.view(*channels_last.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6044e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = width = 32\n",
    "channels_first = rearrange(channels_last,\"batch height width channel->batch channel (height width)\")\n",
    "channels_first_transformed = einsum(channels_first,B,\"batch channel pixel_in, pixel_out pixel_in -> batch channel pixel_out\")\n",
    "channels_last_transformed = rearrange(channels_first_transformed,\"batch channel (height width)->batch height width channel\",height = height,width = width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa5e429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32790cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5bde15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e68579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
